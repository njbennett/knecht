1|done|Refactor: Extract Task struct to its own module
2|done|Write README with usage examples
3|done|Add better error handling with proper Result types
4|done|Commit .knecht/tasks to git
5|done|Tag v0.1 release
6|done|Write .rules file for agent guidance on architecture and design principles (include instructions to fix cargo warnings)
7|done|Consider adding description field (pain count: 1)
8|open|Switch storytime project from beads to knecht
9|done|Normal task without pipes
10|done|Fix test flakiness with parallel execution (pain count: 1)
11|open|Add command to delete/remove tasks (pain count: 2)
12|done|Decide how to handle beads descriptions in knecht migration [addresses blocker in task-8]
13|done|Decide how to handle beads priorities (0-4) in knecht migration [addresses blocker in task-8]
14|done|Decide how to handle beads issue_types (bug/task/epic/feature/chore) [addresses blocker in task-8]
15|done|Write test for beads2knecht migration tool [addresses blocker in task-8]
16|done|Add README documentation for beads2knecht tool [addresses blocker in task-8]
17|done|Add description field to knecht format (pain count: 2 - blocker for task-8)
18|done|Update beads2knecht to preserve descriptions [addresses blocker in task-17]
19|done|Replace bd instructions with knecht in storytime .rules [addresses blocker in task-8]
20|open|Document how to uninstall/remove beads from storytime [addresses blocker in task-8]
21|open|Document multiple binaries setup in README (default-run in Cargo.toml)
22|open|Consider adding test-data/ directory for example files and test fixtures
23|open|Add test helper functions for common test operations (pain count: 3)
24|done|Test task -d Description here
25|done|Test with description
26|done|Simple task without description
27|done|Add refactoring reflection prompt after task completion (pain count: 5)
28|open|Extract Method: CLI argument parsing in cmd_add
29|open|Replace Magic String with Symbolic Constant: pipe delimiter
30|open|Extract Class: TaskSerializer for format parsing/writing
31|done|Restructure to eliminate pipe character validation need
32|open|Consider using clap or similar for CLI argument parsing
33|open|Evaluate migrating from pipe-delimited to JSON Lines format
34|open|Support multi-line descriptions in tasks
35|open|Add 'show' command to display full task details including description (pain count: 2)
36|open|Print task description when starting work on a task (pain count: 2)
37|open|Add commit reminder to 'knecht done' output (pain count: 2)
38|open|Add command to record pain instances on tasks (pain count: 1)
39|open|Review README for redundancy, contradictions, and structure
40|open|Add git pre-commit hook to prompt README review on README changes
41|done|Add pre-commit hook to run tests before allowing commit
42|done|Add test coverage check to pre-commit hook requiring 100% coverage
43|open|Add command to update task title and description
44|open|Add usage instructions to 'knecht list' output for agents
45|open|Improve installation instructions in README -d Current instructions assume user knows about cargo, PATH, /usr/local/bin, and sudo. Add: 1) Prerequisites (Rust/cargo), 2) Step-by-step installation with actual commands, 3) Verification step (which knecht), 4) Troubleshooting common issues (permission denied, PATH not set), 5) Alternative: running via cargo run from source
46|open|Create release process and distribution strategy -d Current: users build from source. Future options: 1) GitHub releases with pre-built binaries for major platforms (macOS, Linux, Windows), 2) Homebrew tap for macOS, 3) cargo install knecht (publish to crates.io), 4) Installation script (curl 
47|done|Fix bug: Task descriptions being silently dropped on read/write -d CRITICAL DATA LOSS BUG: When reading tasks file, if a description contains pipe characters, the description gets silently dropped instead of failing validation. This happened during task-19 session - many task descriptions disappeared. The read logic needs to either: 1) fail/warn on malformed lines, or 2) handle escaped pipes correctly. Write test first that reproduces the bug.
48|open|Make reflection prompt more actionable for agents -d The 'knecht done' reflection prompt asks good questions but agents (including me) ignore it and move on. Need to make it more actionable: 1) Could pause and wait for response, 2) Could be more explicit ('Answer these questions before continuing'), 3) Could be formatted differently to stand out. Pain: Agent (me) just skipped right past reflection prompt after task-19 without responding.
49|open|Evaluate data format complexity - we've reinvented CSV|Current pipe-delimited format with escape sequences is getting complex (split_unescaped, escape/unescape functions). Options: 1) Use actual CSV library (csv crate), 2) Switch to JSON Lines (.jsonl), 3) Switch to more structured format like TOML/YAML, 4) Keep current but document rationale. Consider: git-friendliness, human-readability, simplicity, performance. Pain: Parsing logic is now ~60 lines of custom code that could be 1-2 lines with a library.
99|done|Test
100|open|Show descriptions in list output The 'knecht list' command only shows ID and title. When tasks have descriptions, there's no way to see them without reading the file directly. This makes it hard to understand task context. Possible solutions: add --verbose flag, show first line of description, or add 'knecht show task-N' command.
101|open|Add command to list done tasks Currently 'knecht list' only shows open tasks. There's no way to see completed tasks or verify a task was marked done. Need 'knecht list --done' or 'knecht list --all' to show task history.
102|open|Refactor: Extract Method on test helper setup/teardown Multiple tests repeat the pattern of setup_temp_dir() / run_command() / cleanup_temp_dir(). This is a 'Duplicated Code' smell. Consider 'Extract Method' to create test_in_temp_dir(test_fn) helper that handles setup/teardown. See tests/integration_test.rs.
103|open|Consider simplifying FileSystem trait The FileSystem trait has 5 methods. RealFileSystem is just thin wrappers. This adds indirection without much benefit for production code. Consider 'Inline Class' - could we make the trait internal to tests only? Or is the testability benefit worth the complexity? Track pain points.
104|open|Agent over-engineered solution before user intervention During task-50 (coverage work), agent added FileSystem trait + dependency injection + TestFileSystem (~130 lines) which temporarily LOWERED coverage to 90% because test infrastructure itself had uncovered branches. Agent then tried to use coverage(off) attributes. User had to ask 'Could you write tests for the test code?' to highlight the meta-problem. Only after user pushed back with 'Do we still need the nullables?' did agent properly justify the approach. Problem: Agent didn't pause to validate complexity was necessary before implementing. Agent should have: (1) Explained the tradeoff upfront (2) Asked if user wanted this approach (3) Started with simplest solution. The dependency injection WAS ultimately needed for 100% coverage, but the journey revealed agent needs better complexity-checking behavior.
105|done|Investigate task deletion bug Tasks 1-98 disappeared from .knecht/tasks file. Need to find when/how they were deleted and prevent this from happening. This could be a bug in knecht commands or agent workflow issue.
106|open|Agent workflow caused data loss in commit 5ea0d71 During task-50 (coverage work), commit 5ea0d712 deleted tasks 1-48 and replaced with '99\|open\|Test'. Root cause analysis: Agent likely created test data in .knecht/tasks during testing, then accidentally staged and committed test file instead of preserving real tasks. The commit message makes no mention of tasks file changes, confirming it was unintentional. Evidence: (1) Commit adds extensive test infrastructure with TestFileSystem, (2) '99\|open\|Test' looks like test data not real task, (3) Tests create/modify task files. Impact: Lost 48 tasks but recoverable from git history (commit bb72676). Prevention ideas if this happens again: (1) Pre-commit hook to warn if task count drops significantly, (2) Agent checklist before committing to review staged changes to .knecht/tasks, (3) Keep test data in tests/fixtures/ not .knecht/, (4) Add .knecht/tasks to gitignore during test runs. Track as pain point - if happens again (pain count: 2+), implement prevention.
107|open|Make reflection prompt more actionable for agents (pain count: 2) The 'knecht done' reflection prompt asks good questions but agents (including me) ignore it and move on. Need to make it more actionable: 1) Could pause and wait for response, 2) Could be more explicit ('Answer these questions before continuing'), 3) Could be formatted differently to stand out. Pain instances: (1) Agent skipped past reflection prompt after task-19 without responding, (2) Agent (me) ignored reflection prompt after task-105 even though user explicitly mentioned it. Pattern: Agents treat prompt as optional/informational rather than required work.
108|open|Add pre-commit validation for significant task count drops (pain count: 1) Pre-commit hook should warn if .knecht/tasks loses a significant number of tasks (e.g., drops by >10 tasks). This would have caught the data loss in commit 5ea0d712 where 48 tasks were replaced with 1 test task. Related to task-106. Implementation: hook could count lines before/after staging, or compare with HEAD.
109|done|Isolate test data to prevent accidental commits (pain count: 1) Tests should use isolated temporary directories that can't be accidentally staged/committed. Currently tests can modify .knecht/tasks in project root. Options: (1) Always use temp dirs in tests, (2) Add .knecht/tasks to .gitignore during test runs, (3) Add guard in tests to verify they're not touching production task file. Related to task-106 data loss incident.
110|open|Add task ID sequencing validation (pain count: 1) Add self-check command or automated validation to warn about task ID issues: (1) Non-sequential IDs, (2) Large gaps in sequence (e.g., tasks 1-48 missing, then 99), (3) Duplicate IDs. Could be part of 'knecht list' or a separate 'knecht check' command. Would help detect data integrity issues like the task-106 incident.
111|open|Agents read .knecht/tasks file instead of using knecht list (pain count: 1) Pattern observed: When responding to reflection prompt or checking for existing tasks, agents (including me) often use read_file on .knecht/tasks or grep/cat commands instead of using 'knecht list'. This bypasses knecht's interface and works against the agent-first design principle. The interface should be good enough that agents prefer it over direct file access. Related to task-100 (show descriptions) - agents may read file directly because list output is incomplete. Track pain: if happens repeatedly, need to improve 'knecht list' output to be more useful than raw file.
112|open|Build reflector agent to process session reports into tasks Create a separate agent/process that reads session reports from agents working with knecht and automatically generates tasks based on patterns, pain points, and insights. Problem: Currently relies on agents manually responding to reflection prompts, but agents often ignore them (task-107, pain count: 2). A dedicated reflector could: (1) Parse session logs/transcripts, (2) Identify pain patterns automatically, (3) Generate task descriptions with context, (4) Increment pain counts on existing tasks, (5) Detect refactoring opportunities. Design considerations: Should it run post-session? On-demand? Integrate with knecht or separate tool? What format for session reports? Related to agent-first design principle - make it easier for agents to capture learnings without manual reflection.
113|open|Fix: -d flag in task title wasn't parsed correctly Task-47 has '-d CRITICAL DATA LOSS BUG: ...' in its title, which shows the -d flag wasn't parsed. The agent likely ran something like 'knecht add "Fix bug: Task descriptions being silently dropped" -d "CRITICAL DATA LOSS BUG..."' but the CLI parser didn't recognize -d as a flag. Current implementation may require -d to come before the title, or maybe -d parsing is broken. Need to: (1) Check current arg parsing logic in cmd_add, (2) Write test for 'knecht add TITLE -d DESCRIPTION', (3) Fix if broken, or document correct usage in error messages.
114|open|Add 'knecht search' command to search task titles and descriptions|Pain: During task-114 session, user mentioned 'task-144' but meant 'task-114'. Agent had to grep the file to understand. A search command would help find tasks by keywords: 'knecht search reset' or 'knecht search "tests reset"'. Related to task-111 (agents bypassing knecht interface) and task-100 (need better task discovery).
115|open|Agent over-designed solution - should question necessity before adding complexity|Anti-pattern observed in task-114: Agent tried multiple complex solutions (mutexes, cargo config, subprocess compilation) before user asked 'Why not just remove the wrappers?' The right answer was DELETE CODE, not add complexity. Pattern: Agent was in 'fix the test' mode instead of 'question if we need the test' mode. This violates YAGNI and pain-driven development principles. Refactoring: Need better heuristics/prompts for when to SIMPLIFY vs when to ADD. Related to task-104 (agent over-engineering during task-50). Pain count should track how often agents add unnecessary complexity.
116|open|Add pain count increment command: knecht pain <task-id>|Current pain: To increment pain count on existing task, must manually edit the file. During task-114 reflection, realized task-104 should have pain count incremented from 1 to 2 (second instance of agent over-engineering). Pain tracking is core to pain-driven development but currently requires manual file editing. Need: 'knecht pain 104' to increment count, or 'knecht pain 104 --count 2' to set explicitly. Related to task-38 which was filed earlier with pain count: 1.
